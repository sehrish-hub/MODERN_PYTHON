{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "817221c9",
      "metadata": {
        "id": "817221c9"
      },
      "source": [
        "# L9: Building LLM prompts with variables"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "36029c06",
      "metadata": {
        "id": "36029c06"
      },
      "source": [
        "In the next cell, you will import the function `print_llm_response` that uses an LLM with an instruction that you provide as a string and displays the result."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Y-ATE80jhRkX",
      "metadata": {
        "id": "Y-ATE80jhRkX"
      },
      "source": [
        "### Download helper_function.py\n",
        "* pls set Secrets Variable for Gemini in Collab\n",
        "* `GEMINI_API_KEY`\n",
        "\n",
        "[Get API KEY From Google AI Studio](https://aistudio.google.com/app/apikey)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "aIyjxzPfeiK-"
      },
      "id": "aIyjxzPfeiK-",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "XKKbMtxtg693",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XKKbMtxtg693",
        "outputId": "7f4f245e-213b-4166-f380-bba987e07899"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100  3944  100  3944    0     0  12889      0 --:--:-- --:--:-- --:--:-- 12931\n"
          ]
        }
      ],
      "source": [
        "!curl -o helper_functions.py https://raw.githubusercontent.com/panaversity/learn-cloud-native-modern-ai-python/main/07_natural_language_programming/02_ai_python_for_beginners/course1_basics/Lesson_9/helper_functions.py"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "id": "cc237f34",
      "metadata": {
        "id": "cc237f34"
      },
      "outputs": [],
      "source": [
        "from helper_functions import print_llm_response"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PD134c3yl1eY"
      },
      "id": "PD134c3yl1eY",
      "execution_count": null,
      "outputs": []
    },
    {
      "source": [
        "# helper_functions.py\n",
        "\n",
        "# ... other imports ...\n",
        "\n",
        "import google.generativeai as genai\n",
        "# Instead of fetching the key, assign it directly\n",
        "GEMINI_API_KEY = \"YOUR_GEMINI_API_KEY\" # Replace with your actual API key\n",
        "\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# ... rest of the code ..."
      ],
      "cell_type": "code",
      "metadata": {
        "id": "O6WLSW6vhjat"
      },
      "id": "O6WLSW6vhjat",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print_llm_response(\"What are variables in python?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "4OeTgJqwhOeP",
        "outputId": "32624a60-3a83-44b5-f6e3-f6be7d5addb1"
      },
      "id": "4OeTgJqwhOeP",
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Let's break down variables in Python!\n",
            "\n",
            "**What are Variables?**\n",
            "\n",
            "Think of a variable as a named container that holds a piece of data. In Python, you use variables to store information that your program needs to work with. Here's a simple analogy:\n",
            "\n",
            "* **Imagine a box:** You can label the box \"apple\" and put an actual apple inside. \n",
            "* **Variables are like labeled boxes:**  You give them a name (\"apple\"), and they store a value (the actual apple). \n",
            "\n",
            "**How to Use Variables in Python**\n",
            "\n",
            "1. **Assign a Value:**  You create a variable by assigning a value to it using the `=` operator.\n",
            "\n",
            "   ```python\n",
            "   name = \"Alice\"\n",
            "   age = 30\n",
            "   is_student = True \n",
            "   ```\n",
            "\n",
            "2. **Access the Value:**  You can retrieve the value stored in a variable by simply using its name.\n",
            "\n",
            "   ```python\n",
            "   print(name)  # Output: Alice\n",
            "   print(age)  # Output: 30\n",
            "   print(is_student)  # Output: True\n",
            "   ```\n",
            "\n",
            "**Variable Naming Rules:**\n",
            "\n",
            "* **Start with a letter or underscore (_):**  `my_variable`, `name`, `_count` are valid.\n",
            "* **Can contain letters, numbers, and underscores:**  `my_variable123` is valid.\n",
            "* **Case-sensitive:** `age` and `Age` are different variables.\n",
            "* **Avoid using keywords:**  These are reserved words Python uses (e.g., `if`, `for`, `while`).\n",
            "\n",
            "**Types of Variables (Data Types):**\n",
            "\n",
            "Python has several built-in data types. Here are some common ones:\n",
            "\n",
            "* **Integers:** Whole numbers (e.g., `10`, `-5`, `0`)\n",
            "* **Floats:** Numbers with decimal points (e.g., `3.14`, `-2.5`)\n",
            "* **Strings:** Text enclosed in quotes (e.g., `\"Hello\"`)\n",
            "* **Booleans:** True or False values (e.g., `True`, `False`)\n",
            "\n",
            "**Example:**\n",
            "\n",
            "```python\n",
            "# Store information about a person\n",
            "name = \"Bob\"\n",
            "age = 25\n",
            "city = \"New York\"\n",
            "is_employed = True\n",
            "\n",
            "# Print the person's information\n",
            "print(f\"Name: {name}\")\n",
            "print(f\"Age: {age}\")\n",
            "print(f\"City: {city}\")\n",
            "print(f\"Employed: {is_employed}\") \n",
            "```\n",
            "\n",
            "**Key Points:**\n",
            "\n",
            "* **Reassigning Values:** You can change the value stored in a variable at any time.\n",
            "* **Dynamic Typing:**  You don't need to explicitly declare the data type of a variable in Python.  The interpreter automatically determines the type based on the assigned value.\n",
            "\n",
            "Let me know if you'd like to explore specific data types in more detail, or if you have any other Python concepts you'd like to learn about! \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3074c1f9",
      "metadata": {
        "id": "3074c1f9"
      },
      "source": [
        "Basically, you can use that function as if you were asking a chatbot. You just need to provide your instructions as a string. For instance, you can ask \"What is the capital of France?\" using the following code:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "afcf6686",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "afcf6686",
        "outputId": "de2b53d5-a175-47a6-879f-8674e1b4a262"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The capital of Pakistan is **Islamabad**. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_llm_response(\"What is the capital of pakistan?\")"
      ]
    },
    {
      "source": [
        "# helper_functions.py\n",
        "\n",
        "# ... other imports ...\n",
        "\n",
        "import google.generativeai as genai\n",
        "# Instead of fetching the key, assign it directly\n",
        "GEMINI_API_KEY = \"YOUR_GEMINI_API_KEY\" # Replace with your actual API key\n",
        "\n"
      ],
      "cell_type": "code",
      "metadata": {
        "id": "JYt3XqVqiNmP"
      },
      "id": "JYt3XqVqiNmP",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "7e164d69",
      "metadata": {
        "id": "7e164d69"
      },
      "source": [
        "Let's ask the LLM for the lifestyle description for Otto Matic, whose name is stored in `name`, if he were a `dog_age` years old dog."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "196644ca",
      "metadata": {
        "id": "196644ca"
      },
      "outputs": [],
      "source": [
        "name : str = \"Otto Matic\"\n",
        "dog_age : float  = 21/7"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "id": "ad18f441",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 211
        },
        "id": "ad18f441",
        "outputId": "4a1ef5aa-6d19-4164-d927-eb5632ffe775"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If Otto Matic were a dog, 3.0 years old would put him firmly in **early adulthood**. This is a great time for dogs, full of energy and enthusiasm. \n",
            "\n",
            "**Here's what you might expect from Otto:**\n",
            "\n",
            "* **Energy level:** Otto would be a playful and energetic dog, still eager to explore and learn. He might be less bouncy than a puppy but would still need a good amount of exercise to stay happy and healthy.  Think frisbee-chasing, long walks, and maybe even a romp at the dog park. \n",
            "* **Interests:** Otto might be developing specific interests at this age. He might show a strong preference for certain types of toys, activities, or even other dogs. He could be becoming more independent and confident, exploring his surroundings with a sense of adventure.\n",
            "* **Behavior:** Otto would be a well-socialized dog, capable of understanding commands and learning new tricks. He might be more independent and less prone to destructive behaviors, but still need a good amount of mental stimulation. This is a great time to introduce more complex training and activities.\n",
            "\n",
            "**Overall, 3-year-old Otto would be a fun-loving, active dog with a good sense of curiosity and a desire to learn. He would make a great companion for someone who enjoys spending time outdoors and engaging in activities with their dog.** \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_llm_response(f\"\"\"If {name} were a dog, he would be {dog_age} years old.\n",
        "Describe what life stage that would be for a dog and what that might\n",
        "entail in terms of energy level, interests, and behavior.\"\"\")"
      ]
    },
    {
      "source": [
        "from helper_functions import print_llm_response # Import the print_llm_response function\n",
        "\n",
        "name : str = \"Otto Matic\"\n",
        "dog_age : float  = 21/7\n",
        "\n",
        "print_llm_response(f\"\"\"If {name} were a dog, he would be {dog_age} years old.\n",
        "Describe what life stage that would be for a dog and what that might\n",
        "entail in terms of energy level, interests, and behavior.\"\"\")\n",
        "\n",
        "print_llm_response(\"What is the capital of pakistan?\")"
      ],
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "8_3SU6Zgixpn",
        "outputId": "70234678-7973-424f-a4e7-1ab1ce5926e3"
      },
      "id": "8_3SU6Zgixpn",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "If Otto Matic were a dog, at 3.0 years old he'd be considered a **young adult**. This is a prime time in a dog's life, full of energy and curiosity. \n",
            "\n",
            "Here's what you can expect from Otto in this stage:\n",
            "\n",
            "**Energy Level:** Otto would be brimming with energy. He'd love to play fetch, go for long walks, and explore new places. This is a great time to start training him for agility or other activities that engage his physical and mental abilities.\n",
            "\n",
            "**Interests:** Otto would be keen on learning new things. He'd be eager to please his humans and would be easily trained. This is also the time when he'd be most interested in social interaction with other dogs and people. He might even start showing some playful aggression, which is normal for dogs at this age.\n",
            "\n",
            "**Behavior:** Otto might become a little more independent and assertive. He might test boundaries, but this is also a good time to establish clear rules and boundaries to ensure a well-behaved dog. \n",
            "\n",
            "**Overall:** A 3-year-old dog is generally at the peak of their physical and mental health. They are full of life, playful, and eager to learn. This is a great time to bond with your dog, train them, and enjoy all the wonderful things they have to offer. \n",
            "\n",
            "The capital of Pakistan is **Islamabad**. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "8349cb53",
      "metadata": {
        "id": "8349cb53"
      },
      "source": [
        "<b>You just used AI with your own variables!</b> You used an LLM with instructions that included variables you defined in this notebook.\n",
        "\n",
        "<b>Congratulations ðŸŽ‰ðŸŽ‰ðŸŽ‰</b>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "51181411",
      "metadata": {
        "id": "51181411"
      },
      "source": [
        "## Variable names restrictions"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "89d94522",
      "metadata": {
        "id": "89d94522"
      },
      "source": [
        "The following variable names also have some problems. Try to fix them yourself or use the help from the chatbot."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "id": "af96e951",
      "metadata": {
        "id": "af96e951"
      },
      "outputs": [],
      "source": [
        "driver : str = \"unicorn\"\n",
        "drivers_vehicle : str = \"colorful, asymmetric dinosaur car\"\n",
        "favorite_planet : str = \"Pluto\"\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "driver : str = \"unicorn\"\n",
        "driver_vehicle : str = \"colorful, asymmetric dinosaur car\"\n",
        "favorite_planet : str = \"Pluto\"\n"
      ],
      "metadata": {
        "id": "bzN6sVrXjbhR"
      },
      "id": "bzN6sVrXjbhR",
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "59a3a881",
      "metadata": {
        "id": "59a3a881"
      },
      "source": [
        "Now, update the next cell with any changes you made in the previous cell."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "id": "02b7e02c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 280
        },
        "id": "02b7e02c",
        "outputId": "35b54c09-d0e3-4ab8-f967-5245ef06e4b8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The air buzzed with excitement. It was the day of the Pluto Champion Cup, and the grandstand was packed with cheering fans. The competitors were ready: a dazzling unicorn named Celeste, her horn shimmering with stardust, and a bright, bumpy dinosaur car called Dino-Dash.\n",
            "\n",
            "Celeste, with her flowing mane and graceful strides, was known for her speed and agility. Dino-Dash, though a bit wobbly on its three wheels, was a burst of color, its tail wagging with determination.\n",
            "\n",
            "The starting horn blew, and the race began! Celeste galloped across the track, her hooves barely touching the ground. Dino-Dash, with a loud \"VROOM!\", zoomed alongside, its wheels spitting sparks.\n",
            "\n",
            "The course was tricky. Celeste soared over a rainbow bridge, her horn casting a glimmering trail. Dino-Dash, not quite as graceful, bumped over the bridge, but kept its speed.\n",
            "\n",
            "They dodged flying comets and navigated through a field of glittering stars. Celeste, with her flowing mane, effortlessly maneuvered through the celestial obstacles. Dino-Dash, with its quirky design, bumped and bounced, always finding a way.\n",
            "\n",
            "The finish line was a giant, sparkly moon. Celeste, with a final burst of speed, reached the moon first, her mane shimmering in the moonlight. Dino-Dash, with a final \"VROOM!\", came in a close second, its tail wagging with pride.\n",
            "\n",
            "The crowd roared, celebrating both the swift unicorn and the colorful dinosaur car. Both Celeste and Dino-Dash had shown amazing speed and determination, proving that winning wasn't everything, but the joy of the race was. As the two racers stood side-by-side, they knew, even though they were different, they were both champions. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "print_llm_response(f\"\"\"Write me a 300 word children's story about a {driver} racing\n",
        "a {drivers_vehicle} for the {favorite_planet} champion cup.\"\"\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "my practice"
      ],
      "metadata": {
        "id": "QZFHblhSt-yu"
      },
      "id": "QZFHblhSt-yu"
    },
    {
      "cell_type": "code",
      "source": [
        "# Example response from an LLM (like GPT)\n",
        "llm_response = \"Hello, how can I help you today?\"\n",
        "\n",
        "# Call the print function to display the LLM's response\n",
        "print_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "aZjRO5rrtKhf",
        "outputId": "32a33735-32fe-47ce-a4b5-b34496e7de1e"
      },
      "id": "aZjRO5rrtKhf",
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As a large language model, I don't have personal needs or tasks. However, I'm here to assist you with any questions or tasks you may have. \n",
            "\n",
            "For example, I can:\n",
            "\n",
            "* **Answer your questions** on a wide range of topics.\n",
            "* **Generate creative content** like stories, poems, and scripts.\n",
            "* **Summarize text** and provide insights.\n",
            "* **Translate languages**.\n",
            "* **Help with coding** by suggesting code or debugging it.\n",
            "\n",
            "What would you like to do today? \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "my practice"
      ],
      "metadata": {
        "id": "u3xz6ZIht7EY"
      },
      "id": "u3xz6ZIht7EY"
    },
    {
      "cell_type": "code",
      "source": [
        "def print_llm_response(response):\n",
        "    \"\"\"\n",
        "    Prints the response from a large language model in a formatted way.\n",
        "\n",
        "    Parameters:\n",
        "    response (str): The response string generated by the LLM.\n",
        "    \"\"\"\n",
        "    print(\"LLM Response:\")\n",
        "    print(response)"
      ],
      "metadata": {
        "id": "N7NGiJghtTHw"
      },
      "id": "N7NGiJghtTHw",
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "my practice"
      ],
      "metadata": {
        "id": "JBFV6qkSt3Id"
      },
      "id": "JBFV6qkSt3Id"
    },
    {
      "cell_type": "code",
      "source": [
        "# Example response from an LLM (like GPT)\n",
        "llm_response = \"Hello, how can I help you today?\"\n",
        "\n",
        "# Call the print function to display the LLM's response\n",
        "print_llm_response(llm_response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kKlFvd0VtwAS",
        "outputId": "204dc4a6-6df5-4a43-ff32-ac80ade74ca7"
      },
      "id": "kKlFvd0VtwAS",
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "LLM Response:\n",
            "Hello, how can I help you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "id": "98ec7de7",
      "metadata": {
        "id": "98ec7de7"
      },
      "source": [
        "## Extra practice\n",
        "\n",
        "Try the exercises below to practice the concepts from this lesson. Read the comments in each cell with the instructions for each exercise.\n",
        "\n",
        "<b>Feel free to use the chatbot if you need help.</b>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9fb2bd26",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 108
        },
        "id": "9fb2bd26",
        "outputId": "0e78b88e-175f-4fff-e65f-2240f9bd2cc3"
      },
      "outputs": [
        {
          "ename": "SyntaxError",
          "evalue": "invalid decimal literal (<ipython-input-9-f0ea60fa9964>, line 2)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-9-f0ea60fa9964>\"\u001b[0;36m, line \u001b[0;32m2\u001b[0m\n\u001b[0;31m    1favorite-book : str = \"1001 Ways to Wear a Hat\"\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid decimal literal\n"
          ]
        }
      ],
      "source": [
        "# Fix this code\n",
        "favorite-book : str = \"1001 Ways to Wear a Hat\"\n",
        "\"2002 Ways to Wear a Scarf\" = second_fav_book\n",
        "print(f\"My most favorite book is {1favorite-book}, but I also like {second_fav_book})"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Fix this code\n",
        "favorite_book : str = \"1001 Ways to Wear a Hat\"\n",
        "second_fav_book = \"2002 Ways to Wear a Scarf\"\n",
        "print(f\"My most favorite book is {favorite_book}, but I also like {second_fav_book}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cDCc8-_-oNRh",
        "outputId": "6317016b-27f0-4de0-b04b-60b5aebfd3ac"
      },
      "id": "cDCc8-_-oNRh",
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "My most favorite book is 1001 Ways to Wear a Hat, but I also like 2002 Ways to Wear a Scarf\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "id": "407023e6",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 408
        },
        "id": "407023e6",
        "outputId": "fcfff653-a41d-44f2-8425-8e46d3321344"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "ERROR:tornado.access:500 POST /v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint (127.0.0.1) 3439.13ms\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "InternalServerError",
          "evalue": "500 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mInternalServerError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-30-0d422ef2d352>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# a new song to listen to based on your likes.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m print_llm_response(f\"\"\"\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \"\"\")\n",
            "\u001b[0;32m/content/helper_functions.py\u001b[0m in \u001b[0;36mprint_llm_response\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0;32mand\u001b[0m \u001b[0mpasses\u001b[0m \u001b[0mit\u001b[0m \u001b[0mto\u001b[0m \u001b[0mOpenAI\u001b[0m\u001b[0;31m'\u001b[0m\u001b[0ms\u001b[0m \u001b[0mGPT3\u001b[0m\u001b[0;36m.5\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mfunction\u001b[0m \u001b[0mthen\u001b[0m \u001b[0mprints\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0mof\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \"\"\"\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mllm_response\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_llm_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mllm_response\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/content/helper_functions.py\u001b[0m in \u001b[0;36mget_llm_response\u001b[0;34m(prompt)\u001b[0m\n\u001b[1;32m     39\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Input must be a string enclosed in quotes.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m         \u001b[0mcompletion\u001b[0m  \u001b[0;34m:\u001b[0m \u001b[0mGenerateContentResponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgenerate_content\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompletion\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/generativeai/generative_models.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, contents, generation_config, safety_settings, stream, tools, tool_config, request_options)\u001b[0m\n\u001b[1;32m    329\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mgeneration_types\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGenerateContentResponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_iterator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 331\u001b[0;31m                 response = self._client.generate_content(\n\u001b[0m\u001b[1;32m    332\u001b[0m                     \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m                     \u001b[0;34m**\u001b[0m\u001b[0mrequest_options\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/client.py\u001b[0m in \u001b[0;36mgenerate_content\u001b[0;34m(self, request, model, contents, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    825\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    826\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 827\u001b[0;31m         response = rpc(\n\u001b[0m\u001b[1;32m    828\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    829\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/gapic_v1/method.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, timeout, retry, compression, *args, **kwargs)\u001b[0m\n\u001b[1;32m    129\u001b[0m             \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"compression\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompression\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapped_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_wrapped_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    291\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_initial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maximum\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmultiplier\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_multiplier\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m             )\n\u001b[0;32m--> 293\u001b[0;31m             return retry_target(\n\u001b[0m\u001b[1;32m    294\u001b[0m                 \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    295\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_predicate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m             \u001b[0;31m# defer to shared logic for handling errors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 153\u001b[0;31m             _retry_error_helper(\n\u001b[0m\u001b[1;32m    154\u001b[0m                 \u001b[0mexc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    155\u001b[0m                 \u001b[0mdeadline\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_base.py\u001b[0m in \u001b[0;36m_retry_error_helper\u001b[0;34m(exc, deadline, next_sleep, error_list, predicate_fn, on_error_fn, exc_factory_fn, original_timeout)\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0moriginal_timeout\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    211\u001b[0m         )\n\u001b[0;32m--> 212\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mfinal_exc\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msource_exc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mon_error_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m         \u001b[0mon_error_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/retry/retry_unary.py\u001b[0m in \u001b[0;36mretry_target\u001b[0;34m(target, predicate, sleep_generator, timeout, on_error, exception_factory, **kwargs)\u001b[0m\n\u001b[1;32m    142\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0msleep\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msleep_generator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 144\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    145\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0minspect\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misawaitable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    146\u001b[0m                 \u001b[0mwarnings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ASYNC_RETRY_WARNING\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/timeout.py\u001b[0m in \u001b[0;36mfunc_with_timeout\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    118\u001b[0m                 \u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"timeout\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_timeout\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtime_since_first_attempt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfunc_with_timeout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/api_core/grpc_helpers.py\u001b[0m in \u001b[0;36merror_remapped_callable\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     74\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0merror_remapped_callable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcallable_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mexceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_grpc_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexc\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mexc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/ai/generativelanguage_v1beta/services/generative_service/transports/rest.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, request, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    844\u001b[0m             \u001b[0;31m# subclass.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    845\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus_code\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m400\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 846\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mcore_exceptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_http_response\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    847\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    848\u001b[0m             \u001b[0;31m# Return the response\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mInternalServerError\u001b[0m: 500 POST https://generativelanguage.googleapis.com/v1beta/models/gemini-1.5-flash:generateContent?%24alt=json%3Benum-encoding%3Dint: An internal error has occurred. Please retry or report in https://developers.generativeai.google/guide/troubleshooting"
          ]
        }
      ],
      "source": [
        "# Make variables for your favorite game, movie, and food.\n",
        "# Then use print_llm_response to ask the LLM to recommend you\n",
        "# a new song to listen to based on your likes.\n",
        "\n",
        "print_llm_response(f\"\"\"\n",
        "\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "id": "fr-mvndppVGH",
      "metadata": {
        "id": "fr-mvndppVGH",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 905
        },
        "outputId": "df38ce44-a771-42e6-e715-89e743a8af37"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on your preferences, here are a few song recommendations that could be a good fit:\n",
            "\n",
            "**If you're looking for something upbeat and energetic to match your badminton sessions:**\n",
            "\n",
            "* **\"Bad to the Bone\" by George Thorogood and the Destroyers:** Classic rock with a driving beat and a fun, rebellious attitude.\n",
            "* **\"Feel Good Inc.\" by Gorillaz:** This song blends catchy pop with electronic elements and has a great energy to it.\n",
            "* **\"Can't Stop the Feeling!\" by Justin Timberlake:** Uplifting, catchy pop with a positive message that will make you want to move.\n",
            "\n",
            "**If you prefer something relaxing to enjoy while watching nothing:**\n",
            "\n",
            "* **\"Clair de Lune\" by Claude Debussy:** This classical piece is known for its ethereal beauty and calming melody.\n",
            "* **\"The Scientist\" by Coldplay:** A haunting and reflective song with beautiful piano and strings.\n",
            "* **\"Vienna\" by Billy Joel:** A mellow ballad with a nostalgic feel that's perfect for chilling out.\n",
            "\n",
            "**If you want something fun and cheesy to eat pizza to:**\n",
            "\n",
            "* **\"Pizza My Heart\" by Jay Sean:** A fun and lighthearted pop song with a pizza theme!\n",
            "* **\"Let's Go To The Beach\" by The Shins:** Catchy and upbeat, perfect for a casual summer vibe.\n",
            "* **\"Take On Me\" by a-ha:** Classic 80's synth-pop that's fun and nostalgic. \n",
            "\n",
            "This is just a starting point, and there are many other songs that could fit your preferences.  Tell me more about what kind of mood you're looking for, or if there are any specific genres or artists you enjoy, and I can give you even more tailored recommendations! \n",
            "\n",
            "prompt\n",
            "Based on your preferences, here are a few song recommendations that might appeal to you:\n",
            "\n",
            "**For the \"playing badminton\" vibe:**\n",
            "\n",
            "* **\"Uptown Funk\" by Mark Ronson ft. Bruno Mars:**  This song has a super energetic, upbeat tempo that's perfect for getting pumped up before a game.\n",
            "* **\"Can't Stop the Feeling!\" by Justin Timberlake:**  Another high-energy track that's fun to move to.\n",
            "* **\"Walking on Sunshine\" by Katrina & The Waves:**  This classic has a fun, lighthearted feel that's perfect for a relaxed game of badminton.\n",
            "\n",
            "**For the \"watching nothing\" vibe:**\n",
            "\n",
            "* **\"Slow Dancing in the Dark\" by Joji:** This song has a melancholic, introspective mood that's perfect for relaxing and letting your mind wander.\n",
            "* **\"Clair de Lune\" by Claude Debussy:** This classical piece is incredibly beautiful and calming, perfect for chilling out and zoning out.\n",
            "* **\"The Scientist\" by Coldplay:**  This song has a reflective, almost ethereal feel that's perfect for quiet contemplation.\n",
            "\n",
            "**For the \"eating pizza\" vibe:**\n",
            "\n",
            "* **\"Pizza My Heart\" by The 5.6.7.8's:**  This fun, upbeat instrumental track is perfect for enjoying a delicious pizza.\n",
            "* **\"You Sexy Thing\" by Hot Chocolate:**  This song is a classic for a reason - it's got a fun, flirty vibe that's perfect for enjoying a pizza with friends.\n",
            "* **\"Summertime\" by Ella Fitzgerald:** This classic jazz song is perfect for a relaxed, laid-back pizza night.\n",
            "\n",
            "**For a more general \"chill\" vibe:**\n",
            "\n",
            "* **\"Riptide\" by Vance Joy:** This song is a great mix of mellow and upbeat, perfect for a relaxing evening.\n",
            "* **\"Come Away With Me\" by Norah Jones:** This beautiful, smooth song is perfect for just chilling out and listening to.\n",
            "\n",
            "Remember, these are just a few suggestions! The best song for you will depend on your mood and what you're looking for.  You can also browse through music streaming services like Spotify or Apple Music using keywords like \"chill\", \"relaxed\", \"upbeat\", or \"fun\" to find something you like. \n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Make variables for your favorite game, movie, and food.\n",
        "# Then use print_llm_response to ask the LLM to recommend you\n",
        "# a new song to listen to based on your likes.\n",
        "favorite_game=\"badminton\"\n",
        "favorite_movie=\"nothing\"\n",
        "favorite_food=\"pizza\"\n",
        "print_llm_response(f\"\"\"\n",
        "I enjoy playing {favorite_game}, watching {favorite_movie}, and eating {favorite_food}.\n",
        "Can you recommend a new song based on my preferences?\n",
        "\"\"\")\n",
        "print(\"prompt\")\n",
        "print_llm_response(f\"\"\"\n",
        "I enjoy playing {favorite_game}, watching {favorite_movie}, and eating {favorite_food}.\n",
        "Can you recommend a new song based on my preferences?\n",
        "\"\"\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# prompt: # Make variables for your favorite game, movie, and food.\n",
        "# # Then use print_llm_response to ask the LLM to recommend you\n",
        "# # a new song to listen to based on your likes.\n",
        "\n",
        "favorite_game = \"The Legend of Zelda: Breath of the Wild\"\n",
        "favorite_movie = \"Spirited Away\"\n",
        "favorite_food = \"Sushi\"\n",
        "\n",
        "print_llm_response(f\"\"\"\n",
        "I enjoy playing {favorite_game}, watching {favorite_movie}, and eating {favorite_food}.\n",
        "Can you recommend a new song based on my preferences?\n",
        "\"\"\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "JETARE_ArLr1",
        "outputId": "32561460-3586-4f84-c349-64c9a350bd00"
      },
      "id": "JETARE_ArLr1",
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Based on your interests in The Legend of Zelda: Breath of the Wild, Spirited Away, and Sushi, here are a few song recommendations:\n",
            "\n",
            "**If you like the adventurous, epic feel of Breath of the Wild:**\n",
            "\n",
            "* **\"The Legend of Zelda: Breath of the Wild - Main Theme\" by Manato Shiina:**  This is the official theme song, capturing the game's spirit perfectly. \n",
            "* **\"The Battle of the Pelennor Fields\" from The Lord of the Rings: The Return of the King:** This orchestral piece has a similar sense of scale and grandeur to Breath of the Wild. \n",
            "* **\"The Battle\" by Hans Zimmer:** Another orchestral piece with a thrilling, epic feel that complements the sense of adventure. \n",
            "\n",
            "**If you like the magical, ethereal atmosphere of Spirited Away:**\n",
            "\n",
            "* **\"One Summer's Day\" from Spirited Away:** This beautiful piano piece is iconic from the film and captures its magical feeling. \n",
            "* **\"Clair de Lune\" by Claude Debussy:**  This famous piece has a dreamy, atmospheric quality that echoes the mood of Spirited Away.\n",
            "* **\"Nocturne No. 2 in E-flat Major, Op. 9-2\" by FrÃ©dÃ©ric Chopin:** A romantic and haunting piano piece that complements the film's magical themes.\n",
            "\n",
            "**If you like the delicate and savory flavors of Sushi:**\n",
            "\n",
            "* **\"Kyoto\" by Joep Beving:** This gentle piano piece has a calming, contemplative feel like enjoying a good sushi meal. \n",
            "* **\"The Arrival of the Birds\" by Erik Satie:** This minimalist piece has a delicate and understated beauty, mirroring the refined simplicity of sushi.\n",
            "* **\"Summertime\" by Ella Fitzgerald:** This classic jazz standard evokes a warm, sophisticated feeling similar to a sushi dinner.\n",
            "\n",
            "**Finally, here's one song that combines elements from all your interests:**\n",
            "\n",
            "* **\"The Legend of Zelda: Breath of the Wild - The Great Plateau\" by Manato Shiina:** This piece has a magical and adventurous feel, reminiscent of both the game and Spirited Away. It also has a calm, understated quality, making it perfect for enjoying a sushi dinner.\n",
            "\n",
            "I hope you find a new favorite song from these recommendations! \n",
            "\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.19"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}